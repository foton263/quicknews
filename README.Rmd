---
output:
  md_document:
    variant: markdown_github
---

<!-- badges: start -->
[![Travis build status](https://travis-ci.com/jaytimm/quicknews.svg?branch=main)](https://travis-ci.com/jaytimm/quicknews)
[![R-CMD-check](https://github.com/jaytimm/quicknews/workflows/R-CMD-check/badge.svg)](https://github.com/jaytimm/quicknews/actions)
<!-- badges: end -->


# quicknews 

A simple, lightweight news article extractor, with functions for:

(1) extracting metadata for articles posted on Google News;
(2) scraping online news article content per user-specified URL; and
(3) resolving shortened URLs.



## Installation

You can download the development version from GitHub with:

```{r message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
```


```{r eval=FALSE}
devtools::install_github("jaytimm/quicknews")
```



## Usage

### ยง Google News metadata

The `qnews_get_newsmeta` retrieves metadata from news articles posted to Google News based on user-specified search. Via the `term` parameter. By default, metadata for articles included in the Headlines section are extracted.

```{r}
metas <- quicknews::qnews_get_newsmeta (term = NULL)
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
metas %>%
  arrange(desc(date)) %>%
  select(-link) %>%
  slice(1:5) %>%
  knitr::kable()
```




### ยง Article content

The `qnews_extract_article` function is designed for multi-threaded text extraction from HTML.  The function scrapes web content from URLs specified in the `url` parameter.  Via `rvest` and `xml2`.  A simple approach, with no Java dependencies. HTML markups, comments, extraneous text, etc. are removed mostly via node type, node-final punctuation, character length, and a small dictionary of "junk" phrases.

```{r}
articles <- quicknews::qnews_extract_article(url = metas$link[1:5],
                                             cores = 1)

list(title = strwrap(articles$title[1], width = 60), 
     text = strwrap(articles$text[1], width = 60)[1:5])
```





```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
### ยง Resolve shortened urls

# Shortened URLs are generally encountered in social media.  So, we build a simple demonstration Twitter corpus.

some_tweets <- rtweet::search_tweets2(q = '#Jan6', 
                                      include_rts = F,
                                      n = 1000)
```




```{r eval=FALSE, include=FALSE}
# The `qnews_clean_urls` function extracts source info from URL links and identifies whether or not a link has been shortened.  The latter is based on common shortening practices (eg, bit.ly, goo.gl), and is imperfect.  But false positives here are mostly harmless -- a non-shortened URL will be returned as such.  
# clean_urls <- quicknews::qnews_clean_urls(url = some_tweets$urls_url)

head(clean_urls)
```




```{r eval=FALSE, include=FALSE}
# The `qnews_unshorten_urls` can then be used to resolve shortenened URLs.

shorts <- subset(clean_urls, is_short == 1)
longs <- quicknews::qnews_unshorten_urls(x = shorts$urls_url)

head(longs)
```


