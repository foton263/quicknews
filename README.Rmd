
---
output:
  md_document:
    variant: markdown_github
---

<!-- badges: start -->
[![Travis build status](https://travis-ci.com/jaytimm/quicknews.svg?branch=master)](https://travis-ci.com/jaytimm/quicknews)
<!-- badges: end -->


# quicknews 



Some R-based tools for working with digital media, including functions for:

(1) extracting metadata for articles posted on Google News;
(2) resolving shortened URLs;
(3) scraping online news article content per user-specified URL; and
(4) downloading & summarizing online images.



## Installation

```{r message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
```


```{r eval=FALSE}
devtools::install_github("jaytimm/quicknews")
```



## Usage

### § Google News metadata

The `qnews_get_newsmeta` retrieves metadata from news articles posted to Google News.  There are two search parameters: `term` & `since`.  By default, metadata for articles included in the Headlines section are extracted.  Options for the `since` parameter include `1y`, `1d`, and `7d`.

```{r}
metas <- quicknews::qnews_get_newsmeta (term = NULL, since = NULL)
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
metas %>%
  arrange(desc(date)) %>%
  select(-link) %>%
  slice(1:5) %>%
  knitr::kable()
```




### § Article content

The `qnews_extract_article` functions scrapes web content from URLs specified in the `links` parameter.  Via `rvest` and `xml2`.  The function contains a simple filter for culling html nodes not relevant to article content.  It is not perfect -- no article extractor is -- but no Java dependencies. 

```{r}
articles <- quicknews::qnews_extract_article(metas$link[1:5])

list(title = strwrap(articles$title[1], width = 60), 
     text = strwrap(articles$text[1], width = 60)[1:10])
```

```{r eval=FALSE}
articles2 <- parallel::mclapply(metas$link,
                                quicknews::qnews_extract_article,
                                mc.cores = 6)
```




### § Download images

```{r}
tweets_df1 <- rtweet::search_tweets("#foxitis", 
                                    n = 1000, 
                                    include_rts = F) 

tweet_pics <- tweets_df1 %>% filter(!is.na(media_url)) 
```



```{r message=FALSE, warning=FALSE}
quicknews::img_download_images(link = unlist(tweet_pics$media_url)[1:49], 
                               dir = tempdir(), 
                               prefix = 'foxitis', 
                               scale_border = T)
```




### § Build collage

The `img_build_collage` function builds a collage per a user specified directory of images -- based on the `magick` package and this [post](https://masalmon.eu/2017/03/19/facesofr/).   

```{r fig.height=6, message=FALSE, warning=FALSE}
quicknews::img_build_collage(dir = tempdir(), 
                             dimx = 7, 
                             dimy = 7, 
                             prefix = 'foxitis')
```




### § Google image links

```{r fig.height=6, message=FALSE, warning=FALSE}
search <- 'rino'
links <- quicknews::img_get_gurls(x = search)
```


```{r}
quicknews::img_download_images(link = links, 
                               dir = tempdir(), 
                               prefix = search, 
                               scale_border = T)

quicknews::img_build_collage(dir = tempdir(), 
                             dimx = 5, 
                             dimy = 4, 
                             prefix = search)
```




### § Resolve shortened urls

```{r eval=FALSE}
clean_urls <- quicknews::twt_clean_urls(url = tweets_df1$urls_url)
shorts <- clean_urls %>% filter(is_short == 1)
quicknews::twt_unshorten_urls(x = shorts$urls_url)
